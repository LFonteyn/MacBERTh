@inproceedings{GysBERT_2022,
    title = {Non-Parametric Word Sense Disambiguation for Historical Languages},
    author = {Manjavacas Ar√©valo, Enrique and Fonteyn, Lauren},
    booktitle = {Proceedings of the 2nd Workshop on Natural Language Processing for Digital Humanities (NLP4DH)},
    abstract = {Recent approaches to {Word Sense Disambiguation (WSD)} have profited from the enhanced contextualized word representations coming from contemporary {Large Language Models (LLMs)}. 
    This advancement is accompanied by a renewed interest in {WSD} applications in Humanities research, where the lack of suitable, specific {WSD-annotated} resources is a hurdle in developing ad-hoc {WSD} systems. 
    Because they can exploit sentential context, {LLMs} are particularly suited for disambiguation tasks. 
    Still, the application of {LLMs} is often limited to linear classifiers trained on top of the {LLM} architecture.
    In this paper, we follow recent developments in non-parametric learning and show how {LLMs} can be efficiently fine-tuned to achieve strong few-shot performance on {WSD} for historical languages ({English and Dutch}, date range: 1450-1950). 
    We test our hypothesis using (i) a large, general evaluation set taken from large lexical databases, and (ii) a small real-world scenario involving an ad-hoc {WSD} task. Moreover, this paper marks the release of {GysBERT}, a {LLM} for historical Dutch.}
    month = nov,
    year = "2022",
    publisher = "Association for Computational Linguistics",
    url = "",
    pages = ""
}