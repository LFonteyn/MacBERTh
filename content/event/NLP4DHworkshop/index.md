---
title: Development and Evaluation of a  Historically Pre-trained Language Model for English (1450-1950)

event: NLP4DH
event_url: https://rootroo.com/en/nlp4dh-workshop/

location: Online

summary: This talk introduces MacBERTh, a transformer-based language model pre-trained on historical English. We exhaustively assess the benefits of this historically pre-trained language model on a large set of relevant downstream tasks.
abstract: "The new pre-train-then-fine-tune paradigm in Natural Language Processing (NLP) has made important performance gains accessible to a wider audience. Once pre-trained, deploying a large language model presents comparatively small infrastructure requirements, and offers robust performance in many NLP tasks. The Digital Humanities (DH) community has been an early adapter of this paradigm. Yet, a large part of this community is concerned with the application of NLP algorithms to historical texts, for which large models pre-trained on contemporary text may not provide optimal results. In the present paper, MacBERTh, a transformer-based language model pre-trained on historical English. We exhaustively assess the benefits of this historically pre-trained language model on a large set of relevant downstream tasks. Our experiments highlight that, despite some differences across target time periods, pre-training on historical language from scratch outperforms models pre-trained on present-day language and later adapted to historical language."

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2021-12-16T03:00:00Z"
date_end: "2021-12-19T00:00:00Z"
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: "2017-01-01T00:00:00Z"

authors: [Enrique Manjavacas & Lauren Fonteyn]
tags: []

# Is this a featured talk? (true/false)
featured: false

image:
  caption: 'Image credit: MacBERTh team'
  focal_point: Right

links:
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
# projects:
# - example
---
